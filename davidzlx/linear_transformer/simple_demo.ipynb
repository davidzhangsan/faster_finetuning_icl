{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#####################################################\n",
    "# In this notebook, we train a 3-layer linear transformer with\n",
    "# - context-length 20\n",
    "# - covariate dimension 5, standard Gaussian distribution\n",
    "# We plot\n",
    "# - test loss against number of iterations\n",
    "# - imshow of each parameter matrix at end of training\n",
    "# - distance-to-identity of each parameter matrix\n",
    "#####################################################\n",
    "\n",
    "#use cuda if available, else use cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#torch.cuda.set_device(1)\n",
    "# import the model and some useful functions\n",
    "from linear_transformer import Transformer_F, attention, generate_data, in_context_loss\n",
    "\n",
    "# set up some print options\n",
    "np.set_printoptions(precision = 2, suppress = True)\n",
    "torch.set_printoptions(precision=2)\n",
    "\n",
    "#begin logging\n",
    "log_dir = 'log' \n",
    "#exp_dir = 'simple_demonstration' \n",
    "cur_dir = log_dir #os.path.join(log_dir, exp_dir)\n",
    "os.makedirs(cur_dir, exist_ok=True)\n",
    "#f = open(cur_dir + '/train.log', \"a\", 1)\n",
    "#sys.stdout = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up problem parameters\n",
    "\n",
    "lr = 0.001\n",
    "clip_r = 1000\n",
    "alg = 'adam'\n",
    "mode = 'normal'\n",
    "\n",
    "n_layer = 3  # number of layers of transformer\n",
    "N = 20     # context length\n",
    "d = 5        # dimension\n",
    "\n",
    "\n",
    "n_head = 1  # 1-headed attention\n",
    "B = 4000  # 1000 minibatch size\n",
    "var = 0.0001  # initializations scale of transformer parameter\n",
    "shape_k = 0.1  # shape_k: parameter for Gamma distributed covariates\n",
    "max_iters = 10000  # Number of Iterations to run\n",
    "hist_stride = 1  # stride for saved model paramters in `train.ipynb'\n",
    "stride = 100\n",
    "\n",
    "# a convenience function for taking a step and clipping\n",
    "def clip_and_step(allparam, optimizer, clip_r = None):\n",
    "    norm_p=None\n",
    "    grad_all = allparam.grad\n",
    "    if clip_r is not None:\n",
    "        norm_p = grad_all.norm().item()\n",
    "        if norm_p > clip_r:\n",
    "            grad_all.mul_(clip_r/norm_p)\n",
    "    optimizer.step()\n",
    "    return norm_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_format = '/linearTF_exp_{}_{}_{}.pth'\n",
    "filename = filename_format.format(n_layer, N, d)\n",
    "filename = (cur_dir + filename)\n",
    "hist_dict = {}\n",
    "\n",
    "\n",
    "seeds = [0] #for demonstration purpose, just use 3 seeds\n",
    "keys = [(s,) for s in seeds]\n",
    "for key in keys:\n",
    "    sd = key[0]\n",
    "    \n",
    "    prob_seed = sd\n",
    "    opt_seed = sd\n",
    "    \n",
    "    hist_dict[key] = []\n",
    "    \n",
    "    #set seed and initialize model\n",
    "    torch.manual_seed(opt_seed)\n",
    "    model = Transformer_F(n_layer, 1, d, var)\n",
    "    model.to(device)\n",
    "    #initialize algorithm. Important: set beta = 0.9 for adam, 0.999 is very slow\n",
    "    if alg == 'sgd':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=0)\n",
    "    elif alg == 'adam':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.9), weight_decay=0)\n",
    "    else: assert False\n",
    "    \n",
    "    #set seed and initialize initial training batch\n",
    "    np.random.seed(prob_seed)\n",
    "    torch.manual_seed(prob_seed)\n",
    "    \n",
    "    for t in range(max_iters):\n",
    "        start = time.time()\n",
    "        # save model parameters\n",
    "        if t%hist_stride ==0:\n",
    "            hist_dict[key].append(model.allparam.clone().detach())\n",
    "        #  generate a new batch of training set\n",
    "        Z, y = generate_data(mode,N,d,B,shape_k)\n",
    "        Z = Z.to(device)\n",
    "        y = y.to(device)\n",
    "        loss = in_context_loss(model, Z, y)\n",
    "        \n",
    "        # compute gradient, take step\n",
    "        loss.backward()\n",
    "        norms = clip_and_step(model.allparam, optimizer, clip_r=clip_r)\n",
    "        optimizer.zero_grad()\n",
    "        end=time.time()\n",
    "        if t%100 ==0 or t<5:\n",
    "            print('iter {} | Loss: {}  time: {}  gradnorm: {}'.format(t,loss.item(), end-start, norms))\n",
    "    #save to \n",
    "torch.save({'hist_dict':hist_dict}, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# compute test loss\n",
    "####################################\n",
    "hist_dict = torch.load(filename)['hist_dict']\n",
    "loss_dict = {}\n",
    "for key in hist_dict:\n",
    "    sd = key[0]\n",
    "    \n",
    "    loss_dict[key] = torch.zeros(max_iters//stride)\n",
    "    \n",
    "    np.random.seed(99)\n",
    "    torch.manual_seed(99)\n",
    "    Z, y = generate_data(mode,N,d,B,shape_k)\n",
    "    Z = Z.to(device)\n",
    "    y = y.to(device)\n",
    "    model = Transformer_F(n_layer, n_head, d, var).to(device)\n",
    "    for t in range(0,max_iters,stride):\n",
    "        with torch.no_grad():\n",
    "            model.allparam.copy_(hist_dict[key][t])\n",
    "        loss_dict[key][t//stride] = in_context_loss(model, Z, y).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# plot the test loss with error bars\n",
    "####################################\n",
    "\n",
    "fig_dir = 'figures' \n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1,figsize = (7, 6))\n",
    "\n",
    "losses = torch.zeros(len(seeds), max_iters//stride)\n",
    "keys = loss_dict.keys()\n",
    "for idx, key in enumerate(keys):\n",
    "    losses[idx,:] = loss_dict[key]\n",
    "losses_mean = torch.mean(losses, axis=0)\n",
    "losses_std = torch.std(losses, axis=0)\n",
    "ax.plot(range(0,max_iters,stride), losses_mean, color = 'red', lw = 3)#, label='Adam')\n",
    "ax.fill_between(range(0,max_iters,stride), losses_mean-losses_std, losses_mean+losses_std, color = 'red', alpha = 0.2)\n",
    "ax.set_xlabel('Iteration',fontsize=40)\n",
    "ax.set_ylabel('ICL Test Loss',fontsize=40)\n",
    "ax.tick_params(axis='both', which='major', labelsize=30, width = 3, length = 10)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=20, width = 3, length = 5)\n",
    "#ax.legend(fontsize=30)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + '/simple_demonstration_loss_plot.pdf', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# display the parameter matrices\n",
    "# image/font setting assumes d=5\n",
    "####################################\n",
    "\n",
    "key = (0,)\n",
    "for l in range(n_layer-1):\n",
    "    for h in range(n_head):\n",
    "        fig, ax = plt.subplots(1, 1,figsize = (6, 6))\n",
    "        matrix = hist_dict[key][9999][l,h,0,:,:]\n",
    "        # Create a heatmap using imshow\n",
    "        im = ax.imshow(matrix.cpu(), cmap='gray_r')\n",
    "        # Add the matrix values as text\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(matrix.shape[1]):\n",
    "                ax.text(j, i, format(matrix[i, j], '.2f'), ha='center', va='center', color='r')\n",
    "        # Add a colorbar for reference\n",
    "        fig.colorbar(im)\n",
    "        ax.set_title('$B_{}$'.format(l),fontsize=20)\n",
    "        \n",
    "        plt.savefig(fig_dir + '/simple_demonstration_B{}.pdf'.format(l), dpi=600)\n",
    "for l in range(n_layer):\n",
    "    for h in range(n_head):\n",
    "        fig, ax = plt.subplots(1, 1,figsize = (6, 6))\n",
    "        matrix = hist_dict[key][9999][l,h,1,:,:]\n",
    "        # Create a heatmap using imshow\n",
    "        im = ax.imshow(matrix.cpu(), cmap='gray_r')\n",
    "        # Add the matrix values as text\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(matrix.shape[1]):\n",
    "                ax.text(j, i, format(matrix[i, j], '.2f'), ha='center', va='center', color='r')\n",
    "        # Add a colorbar for reference\n",
    "        fig.colorbar(im)\n",
    "        ax.set_title('$A_{}$'.format(l),fontsize=20)\n",
    "        plt.savefig(fig_dir + '/simple_demonstration_A{}.pdf'.format(l), dpi=600)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# plot the distance-to-identity of each matrix with time\n",
    "########################################################\n",
    "\n",
    "# function for computing distance to identity\n",
    "def compute_dist_identity(M):\n",
    "    scale = torch.sum(torch.diagonal(M))/M.shape[0]\n",
    "    ideal_identity = scale* torch.eye(M.shape[0]).to(device)\n",
    "    difference = M - ideal_identity\n",
    "    err = (torch.norm(difference,p='fro')/torch.norm(M,p='fro')).item()\n",
    "    return err\n",
    "\n",
    "########################################\n",
    "# compute distances (assume n_head = 1)\n",
    "########################################\n",
    "dist_dict = {}\n",
    "            \n",
    "for key in hist_dict:\n",
    "    (sd,) = key\n",
    "    dist_dict[key] = torch.zeros(n_layer, 2, max_iters//stride)\n",
    "\n",
    "    for t in range(0,max_iters,stride):\n",
    "        with torch.no_grad():\n",
    "            allparam = hist_dict[key][t]\n",
    "        for i in range(n_layer):\n",
    "            for j in range(2):\n",
    "                dist_dict[key][i,j,t//stride] = compute_dist_identity(allparam[i,0,j,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################\n",
    "# plot distances\n",
    "####################################\n",
    "\n",
    "fig_dir = 'figures' \n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2,figsize = (14, 18))\n",
    "\n",
    "labels = ['B0', 'B1', None, 'A0', 'A1', 'A2']\n",
    "colors = ['red','orange',None, 'green','blue','black']\n",
    "\n",
    "labels = ['B0', 'B1', None, 'A0', 'A1', 'A2']\n",
    "colors = ['red','orange',None, 'green','blue','black']\n",
    "\n",
    "#make P plots\n",
    "for l in range(n_layer):\n",
    "    for pq in range(2):\n",
    "        if l==n_layer-1 and pq==0:\n",
    "            continue\n",
    "        ax = axs[l,pq]\n",
    "        dist_p = torch.zeros(len(seeds), max_iters//stride)\n",
    "        for idx, sd in enumerate(seeds):\n",
    "            losses[idx,:] = dist_dict[(sd,)][l,pq,:]\n",
    "        dist_mean = torch.mean(losses, axis=0)\n",
    "        dist_std = torch.std(losses, axis=0)\n",
    "        \n",
    "        style_id = l + 3*pq\n",
    "        \n",
    "        ax.plot(range(0,max_iters,stride), dist_mean, color = colors[style_id], lw = 3, label=labels[style_id])\n",
    "        ax.fill_between(range(0,max_iters,stride), dist_mean-dist_std, dist_mean+dist_std, color = colors[style_id], alpha = 0.2)\n",
    "        #ax.set_xlabel('Iteration',fontsize=40)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20, width = 3, length = 10)\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=20, width = 3, length = 5)\n",
    "        ax.legend(fontsize=30)\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "plt.savefig(fig_dir + '/simple_demonstration_dist_to_id.pdf', dpi=600)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers_icl_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
